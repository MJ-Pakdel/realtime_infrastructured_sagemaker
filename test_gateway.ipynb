{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "curl -X POST https://9jgdg7ysyh.execute-api.us-east-1.amazonaws.com/prod/ \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"instances\":[[0.5,-1.2,3.3,0.0,2.1,-0.7,4.4,5.5]]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing API Gateway URL: https://u7a3rzm4q2.execute-api.us-east-1.amazonaws.com/\n",
      "P10 latency: 124.24 ms\n",
      "P50 latency: 127.87 ms\n",
      "P90 latency: 132.28 ms\n",
      "P95 latency: 135.04 ms\n",
      "P99 latency: 139.10 ms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import subprocess\n",
    "import sys\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def get_api_url():\n",
    "    \"\"\"Read the base invoke URL from Terraform outputs.\"\"\"\n",
    "    try:\n",
    "        raw = subprocess.check_output(\n",
    "            [\"terraform\", \"output\", \"-raw\", \"api_gateway_url\"],\n",
    "            stderr=subprocess.STDOUT\n",
    "        )\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"❌ Failed to read Terraform output:\", e.output.decode(), file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "    return raw.decode().strip().rstrip(\"/\") + \"/\"\n",
    "\n",
    "def measure_latency(url, features, n_requests=100, warmup=50):\n",
    "    \"\"\"\n",
    "    Sends `warmup` unmeasured requests, then `n_requests` timed requests\n",
    "    over a single HTTP connection, and prints P10/P50/P90/P95.\n",
    "    \"\"\"\n",
    "    session = requests.Session()   # reuse TCP/TLS connection\n",
    "    payload = {\"features\": features}\n",
    "\n",
    "    # warm-up (no timing)\n",
    "    for _ in range(warmup):\n",
    "        session.post(url, json=payload)\n",
    "\n",
    "    # measured run\n",
    "    latencies = []\n",
    "    for _ in range(n_requests):\n",
    "        start = time.perf_counter()\n",
    "        r = session.post(url, json=payload)\n",
    "        if not r.ok:\n",
    "            print(\"Error:\", r.status_code, r.text)\n",
    "            break\n",
    "        latencies.append((time.perf_counter() - start) * 1000)\n",
    "\n",
    "    for pct in (10, 50, 90, 95, 99):\n",
    "        print(f\"P{pct} latency: {np.percentile(latencies, pct):.2f} ms\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = get_api_url()\n",
    "    print(\"Testing API Gateway URL:\", url)\n",
    "    # example features—adjust to match your model\n",
    "    test_features = [0.5, -1.2, 3.3, 0.0, 2.1, -0.7, 4.4, 5.5]\n",
    "    measure_latency(url, test_features,n_requests=100)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
